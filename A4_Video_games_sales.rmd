---
title: "Assignment 4 - Video Game Sales"
author: "Britney Nguyet Dang"
date: '2022-06-13'
output: 
  html_document:
    theme: readable
    highlight: breezedark
    number_sections: yes
    toc: yes
    fig_width: 10
    fig_height: 5
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Set up, data import, data exploration, data partitioning, and inspection code
```{r Set up, data import, data exploration, data partitioning, and inspection code}
#1A 
## Package loading
library(rmarkdown)
library(psych)
library(rpart)
library(rpart.plot)
library(RWeka)
library(rJava)
library(caret)
library(ggplot2)
library(lattice)
library(rminer)
library(matrixStats)
library(knitr)
library(tictoc)
tic()

## Set directory
mydir <- getwd()
setwd(mydir)

## Data import (Load character strings as character fields)
game_data_noname <- read.csv(file="NA_sales_filtered.csv",stringsAsFactors = FALSE)

## Overall structure and summary of the input data
str(game_data_noname)
summary(game_data_noname)

## Data transformation (Transform all other non-numeric fields to be factor variables)
game_data_noname$Platform <- factor(game_data_noname$Platform)
game_data_noname$Genre <- factor(game_data_noname$Genre)
game_data_noname$Rating <- factor(game_data_noname$Rating)

#1B Show distributions and correlations of all of the numeric variables
## Distribution
hist(game_data_noname$NA_Sales)

## Correlations using pairs.panels of all of the numeric variables
cor(game_data_noname[c("Critic_Score","Critic_Count","User_Score","User_Count","NA_Sales")])
pairs.panels(game_data_noname)

#1C Remove the Name variable from the data frame and build a linear regression model
## Remove the Name variable from the data frame
game_data_noname$Name <- NULL

## Build linear model (without "Name")
lm1 <- lm(NA_Sales~Platform+Genre+Rating+Critic_Score+Critic_Count+User_Score+User_Count,data = game_data_noname)

## Summary
summary(lm1)

#1D Partition the dataset for simple hold-out evaluation
set.seed(500)
training70 <- createDataPartition(y=game_data_noname$NA_Sales,p=0.70,list=FALSE)
training_target <- game_data_noname[training70,8]
training_input <- game_data_noname[training70,-8]
testing_target <- game_data_noname[-training70,8]
testing_input <- game_data_noname[-training70,-8]

#1E Summary of overall
summary(training_target)
summary(training_input)
summary(testing_target)
summary(testing_input)
```

# lm, rpart and M5P model training and testing
```{r lm, rpart and M5P model training and testing}
#2A Train three models using lm, rpart and M5P
## Using lm
train_lm_model <- lm(training_target~.,data=training_input)

## Using rpart
train_rpart_model <- rpart(training_target~.,data=training_input)

## Using M5P
train_m5p_model <- M5P(training_target~.,data=training_input)

#2B Perform the following for the three models
##2Bi Show model info and summary
### lm
train_lm_model
summary(train_lm_model)

### rpart
train_rpart_model
summary(train_rpart_model)

### M5P
train_m5p_model
summary(train_m5p_model)

##2Bii Apply predictive model, generate the model-fit and prediction error metrics in the testing and training sets
### lm
prediction_test_lm_model <- predict(train_lm_model,testing_input)
summary(prediction_test_lm_model)
prediction_train_lm_model <- predict(train_lm_model,training_input)
summary(prediction_train_lm_model)

mmetric(testing_target,prediction_test_lm_model,c("MAE","MAPE","RAE","RMSE","RMSPE","RRSE","R2"))
mmetric(training_target,prediction_train_lm_model,c("MAE","MAPE","RAE","RMSE","RMSPE","RRSE","R2"))

### rpart
prediction_test_rpart_model <- predict(train_rpart_model,testing_input)
summary(prediction_test_rpart_model)
prediction_train_rpart_model <- predict(train_rpart_model,training_input)
summary(prediction_train_rpart_model)

mmetric(testing_target,prediction_test_rpart_model,c("MAE","MAPE","RAE","RMSE","RMSPE","RRSE","R2"))
mmetric(training_target,prediction_train_rpart_model,c("MAE","MAPE","RAE","RMSE","RMSPE","RRSE","R2"))

### M5P
prediction_test_m5p_model <- predict(train_m5p_model,testing_input)
summary(prediction_test_m5p_model)
prediction_train_m5p_model <- predict(train_m5p_model,training_input)
summary(prediction_train_m5p_model)

mmetric(testing_target,prediction_test_m5p_model,c("MAE","MAPE","RAE","RMSE","RMSPE","RRSE","R2"))
mmetric(training_target,prediction_train_m5p_model,c("MAE","MAPE","RAE","RMSE","RMSPE","RRSE","R2"))
```

# Cross-validation of lm, rpart, and M5P NA_Sales prediction models
```{r Cross-validation of lm, rpart, and M5P NA_Sales prediction models}
#3A Define a named function for cross-validation of numeric prediction models that generates a table of the model fit and error metrics specified in 2B for each fold along with the means and standard deviations of the metrics over all of the folds
## Define cv_function
cv_function <- function(df, target, nFolds, seedVal, prediction_method, metrics_list)
{
  set.seed(seedVal)
  folds = createFolds(df[,target],nFolds) 
  cv_results <- lapply(folds, function(x)
  { 
    test_target <- df[x,target]
    test_input  <- df[x,-target]
    train_target <- df[-x,target]
    train_input <- df[-x,-target]

    prediction_model <- prediction_method(train_target~.,train_input) 
    pred<- predict(prediction_model,test_input)
    return(mmetric(test_target,pred,metrics_list))
  })
  
  cv_results_m <- as.matrix(as.data.frame(cv_results))
  cv_mean<- as.matrix(rowMeans(cv_results_m))
  cv_sd <- as.matrix(rowSds(cv_results_m))
  colnames(cv_mean) <- "Mean"
  colnames(cv_sd) <- "Sd"
  cv_all <- cbind(cv_results_m, cv_mean, cv_sd)
  kable(t(cv_all),digits=2)
}

## Call cv_function for 5-fold cross-validation result for NA_Sales (position 8 in game_data_noname)
df <- game_data_noname
target <- 8
nFolds <- 5
seedVal <- 500
metrics_list <- c("MAE","MAPE","RAE","RMSE","RMSPE","RRSE","R2")

### lm 
prediction_method <- lm
cv_function(df, target, 5, seedVal, prediction_method, metrics_list)

### rpart
prediction_method <- rpart
cv_function(df, target, 5, seedVal, prediction_method, metrics_list)

### M5P
prediction_method <- M5P
cv_function(df, target, 5, seedVal, prediction_method, metrics_list)
```

# Improve the models by adding a quadratic term of Critic_Score
```{r Improve the models by adding a quadratic term of Critic_Score}
# 4A Create and add the quadratic term of Critic_Score (Critic_Score_Squared) to the predictors for NA_Sales
game_data_noname$Critic_Score2 <- game_data_noname$Critic_Score^2

# 4B Build an lm model using the whole data set that includes Critic_Score_Squared to predict NA_Sales
## Partition the new dataset (training 70%)
set.seed(500)
train70_v1 <- createDataPartition(y=game_data_noname$NA_Sales,p=0.70,list = FALSE)
train_input1 <- game_data_noname[train70_v1,-8]
train_target1 <- game_data_noname[train70_v1,8]
test_input1 <- game_data_noname[-train70_v1,-8]
test_target1 <- game_data_noname[-train70_v1,8]

## Create an improved lm on train dataset
improve_train_lm_model1 <- lm(train_target1~Platform+Genre+Rating+Critic_Score+Critic_Count+User_Score+User_Count+Critic_Score2,data = train_input1)

## Show summary
summary(improve_train_lm_model1)

# 4C Call cv_function defined for 3A to generate 5-fold cross-validation results with Critic_Score_Squared
df <- game_data_noname
target <- 8
nFolds <- 5
seedVal <- 500
metrics_list <- c("MAE","MAPE","RAE","RMSE","RMSPE","RRSE","R2")

## lm
prediction_method <- lm
cv_function(df, target, 5, seedVal, prediction_method, metrics_list)

## rpart
prediction_method <- rpart
cv_function(df, target, 5, seedVal, prediction_method, metrics_list)

## M5P
prediction_method <- M5P
cv_function(df, target, 5, seedVal, prediction_method, metrics_list)
```

# Improve the models with the log term of User_Count
```{r Improve the models with the log term of User_Count}
# 5A Create and add the natural log transformation of User_Count (log_User_Count) to the predictors for the target variable
## Remove the original User_Count (position 7) and Critic_Count_Squared (position 9)

df_log_User_Count <- game_data_noname[,c(-7,-9)]

## Create and add the natural log transformation of User_Count
df_log_User_Count$log_User_Count <- log(game_data_noname$User_Count)

# 5B Build an lm model with the whole data set that includes log_User_Count
## Partition the new dataset (training 70%)
set.seed(500)
train70_v2 <- createDataPartition(y=df_log_User_Count$NA_Sales,p=0.70,list = FALSE)
train_input2 <- df_log_User_Count[train70_v2,-7]
train_target2 <- df_log_User_Count[train70_v2,7]
test_input2 <- df_log_User_Count[-train70_v2,-7]
test_target2 <- df_log_User_Count[-train70_v2,7]

## Create an improved lm on train dataset
improve_train_lm_model2 <- lm(train_target2~Platform+Genre+Rating+Critic_Score+Critic_Count+User_Score+log_User_Count,data = train_input2)

## Show summary
summary(improve_train_lm_model2)

# 5C Call cv_function defined for 3A to generate 5-fold cross-validation results with log_User_Count
df <- df_log_User_Count
target <- 7
nFolds <- 5
seedVal <- 500
metrics_list <- c("MAE","MAPE","RAE","RMSE","RMSPE","RRSE","R2")

## lm
prediction_method <- lm
cv_function(df, target, 5, seedVal, prediction_method, metrics_list)

## rpart
prediction_method <- rpart
cv_function(df, target, 5, seedVal, prediction_method, metrics_list)

## M5P
prediction_method <- M5P
cv_function(df, target, 5, seedVal, prediction_method, metrics_list)
```

