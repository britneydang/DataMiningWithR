---
title: "Assignment 5 - Video Game Sales"
author: "Britney Nguyet Dang"
date: '2022-06-26'
output: 
  html_document:
    theme: readable
    highlight: breezedark
    number_sections: yes
    toc: yes
    fig_width: 15
    fig_height: 10
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Package load, data import, inspection, and partitioning
```{r Package load, data import, inspection, and partitioning}
#1A Package load
library(caret) 
library(RWeka) 
library(rJava)
library(kernlab)
library(rminer) 
library(matrixStats) 
library(knitr)
library(tictoc)
tic()

#1B
## Set directory
mydir <- getwd()
setwd(mydir)

## Data import
game_data <- read.csv(file="NA_sales_filtered.csv",stringsAsFactors = FALSE)

## Remove "Name"
game_data$Name <- NULL
str(game_data)

## Transform character variables into factor variables
game_data$Platform <- factor(game_data$Platform)
game_data$Genre <- factor(game_data$Genre)
game_data$Rating <- factor(game_data$Rating)

## Create training (70%) and testing sets
set.seed(500)
training70 <- createDataPartition(y=game_data$NA_Sales,p=0.70,list=FALSE)
training_target <- game_data[training70,8]
training_input <- game_data[training70,-8]
testing_target <- game_data[-training70,8]
testing_input <- game_data[-training70,-8]
```

# Build and evaluate neural network models for numeric prediction tasks
```{r Build and evaluate neural network models for numeric prediction tasks}
#2A Neural network models for numeric prediction tasks
## i - Build MLP model using default setting (l=0.3,m=0.2,n=500,h='a') 
### Designate a short name MLP
MLP <- make_Weka_classifier("weka/classifiers/functions/MultilayerPerceptron")

### Build MLP model
MLP_train <- MLP(training_target~.,data=training_input)

### Parameters for MLP model_a
l <- 0.3
m <- 0.2
n <- 500
h <- 'a'

### Model using default values
model_a_train <- MLP(training_target~.,data=training_input,control=Weka_control(L=l,M=m,N=n,H=h))
summary(model_a_train)

### Evaluate model a performance
metrics_list <- c("MAE","RMSE","MAPE","RMSPE","RAE","RRSE","R2")

test_a_pred <- predict(model_a_train,testing_input)
mmetric(testing_target,test_a_pred,metrics_list)

train_a_pred <- predict(model_a_train,training_input)
mmetric(training_target,train_a_pred,metrics_list)

## ii - Build 2-hidden layer MLP model and change 1 of the other hyper-parameter value
### Parameters for new MLP model
l <- 1
m <- 0.2
n <- 500
h <- 'a,a'

### Model using 2-hidden layer and l = 1
model_a_a_train <- MLP(training_target~.,data=training_input,control=Weka_control(L=l,M=m,N=n,H=h))
summary(model_a_a_train)

### Evaluate model a a performance
metrics_list <- c("MAE","RMSE","MAPE","RMSPE","RAE","RRSE","R2")

test_aa_pred <- predict(model_a_train,testing_input)
mmetric(testing_target,test_aa_pred,metrics_list)

train_aa_pred <- predict(model_a_train,training_input)
mmetric(training_target,train_aa_pred,metrics_list)
```

# Build and evaluate SVM (ksvm) models for numeric prediction tasks
```{r Build and evaluate SVM (ksvm) models for numeric prediction tasks}
#3A SVM (ksvm) models for numeric prediction tasks
## i - Build SVM model using default setting (kernel = "rbfdot" and C = 1)
set.seed(500)
SVM_train <- ksvm(training_target~.,data=training_input)
SVM_train

## ii - Build SVM model using a different kernel and C = 1
### Training set
set.seed(500)
SVM_train_1 <- ksvm(training_target~.,data=training_input,kernel="polydot",C=1)
SVM_train_1

set.seed(500)
SVM_train_2 <- ksvm(training_target~.,data=training_input,kernel="laplacedot",C=1)
SVM_train_2

### Evaluate model performance
metrics_list <- c("MAE","RMSE","MAPE","RMSPE","RAE","RRSE","R2")

#### kernel = "polydot"
test_SVM1_pred <- predict(SVM_train,testing_input)
mmetric(testing_target,test_SVM1_pred,metrics_list)
train_SVM1_pred <- predict(SVM_train,training_input)
mmetric(training_target,train_SVM1_pred,metrics_list)

#### kernel = "laplacedot"
test_SVM2_pred <- predict(SVM_train,testing_input)
mmetric(testing_target,test_SVM2_pred,metrics_list)
train_SVM2_pred <- predict(SVM_train,training_input)
mmetric(training_target,train_SVM2_pred,metrics_list)

## iii - Build SVM model using a different cost value (C > 1)
### Training set
set.seed(500)
SVM_train_3 <- ksvm(training_target~.,data=training_input,kernel="polydot",C=20)
SVM_train_3

set.seed(500)
SVM_train_4 <- ksvm(training_target~.,data=training_input,kernel="laplacedot",C=20)
SVM_train_4

### Evaluate model performance
metrics_list <- c("MAE","RMSE","MAPE","RMSPE","RAE","RRSE","R2")

#### kernel = "polydot"
test_SVM3_pred <- predict(SVM_train,testing_input)
mmetric(testing_target,test_SVM3_pred,metrics_list)
train_SVM3_pred <- predict(SVM_train,training_input)
mmetric(training_target,train_SVM3_pred,metrics_list)

#### kernel = "laplacedot"
test_SVM4_pred <- predict(SVM_train,testing_input)
mmetric(testing_target,test_SVM4_pred,metrics_list)
train_SVM4_pred <- predict(SVM_train,training_input)
mmetric(training_target,train_SVM4_pred,metrics_list)
```

# Build and evaluate knn (IBk) models for numeric prediction tasks
```{r Build and evaluate knn (IBk) models for numeric prediction tasks}
metrics_list <- c("MAE","RMSE","MAPE","RMSPE","RAE","RRSE","R2")

## i - Build KNN (iBk) model using default setting
### Training set
knn_base_model <- IBk(training_target~.,data = training_input)
knn_base_model

### Evaluate base model performance
test_base_pred <- predict(knn_base_model,testing_input)
mmetric(testing_target,test_base_pred,metrics_list)

train_base_pred <- predict(knn_base_model,training_input)
mmetric(training_target,train_base_pred,metrics_list)

## ii - Build KNN (iBk) model using different K and other parameters at the default setting
### Training set
knn_k2_model <- IBk(training_target~.,data = training_input,control = Weka_control(K=2))
knn_k2_model

### Evaluate K=2 model performance
test_k2_pred <- predict(knn_k2_model,testing_input)
mmetric(testing_target,test_k2_pred,metrics_list)

train_k2_pred <- predict(knn_k2_model,training_input)
mmetric(training_target,train_k2_pred,metrics_list)

## iii - Build KNN (iBk) model using a weighted voting approach I=TRUE
### Training set
knn_k20i_model <- IBk(training_target~.,data = training_input,control = Weka_control(K=20,I=TRUE))
knn_k20i_model

### Evaluate K=20 I=TRUE model performance
test_k20i_pred <- predict(knn_k20i_model,testing_input)
mmetric(testing_target,test_k20i_pred,metrics_list)

train_k20i_pred <- predict(knn_k20i_model,training_input)
mmetric(training_target,train_k20i_pred,metrics_list)

## iv - Build KNN (iBk) model using automate K selection X=TRUE
### Training set
knn_k20x_model <- IBk(training_target~.,data = training_input,control = Weka_control(K=20,X=TRUE))
knn_k20x_model

### Evaluate K=20 I=TRUE model performance
test_k20x_pred <- predict(knn_k20x_model,testing_input)
mmetric(testing_target,test_k20x_pred,metrics_list)

train_k20x_pred <- predict(knn_k20x_model,training_input)
mmetric(training_target,train_k20x_pred,metrics_list)
```

# Cross-validation function for numeric prediction models
```{r Cross-validation function for numeric prediction models}
#5AB Define a named function for cv evaluation of models
## cv_function for MLP model
cv_function_MLP <- function(df, target, nFolds, seedVal, metrics_list, l, m, n, h)
{
  set.seed(seedVal)
  folds = createFolds(df[,target],nFolds) 
  cv_results_MLP <- lapply(folds, function(x)
  { 
    test_target <- df[x,target]
    test_input  <- df[x,-target]
    train_target <- df[-x,target]
    train_input <- df[-x,-target]

    prediction_model_MLP <- MLP(train_target~.,data = train_input, control = Weka_control(L=l,M=m,N=n,H=h)) 
    pred_MLP <- predict(prediction_model_MLP,test_input)
    return(mmetric(test_target,pred_MLP,metrics_list))
  })
  
  cv_results_MLP <- as.matrix(as.data.frame(cv_results_MLP))
  cv_mean_MLP <- as.matrix(rowMeans(cv_results_MLP))
  cv_sd_MLP <- as.matrix(rowSds(cv_results_MLP))
  colnames(cv_mean_MLP) <- "Mean"
  colnames(cv_sd_MLP) <- "Sd"
  cv_all_MLP <- cbind(cv_results_MLP, cv_mean_MLP, cv_sd_MLP)
  kable(t(cv_all_MLP),digits=2)
}

## cv_function for SVM (ksvm) model
cv_function_ksvm <- function(df, target, nFolds, seedVal, metrics_list, kern, c)
{
  set.seed(seedVal)
  folds = createFolds(df[,target],nFolds) 
  cv_results_ksvm <- lapply(folds, function(x)
  { 
    test_target <- df[x,target]
    test_input  <- df[x,-target]
    train_target <- df[-x,target]
    train_input <- df[-x,-target]

    prediction_model_ksvm <- ksvm(train_target~.,data = train_input, kernel = kern, C = c) 
    pred_ksvm <- predict(prediction_model_ksvm,test_input)
    return(mmetric(test_target,pred_ksvm,metrics_list))
  })
  
  cv_results_ksvm <- as.matrix(as.data.frame(cv_results_ksvm))
  cv_mean_ksvm <- as.matrix(rowMeans(cv_results_ksvm))
  cv_sd_ksvm <- as.matrix(rowSds(cv_results_ksvm))
  colnames(cv_mean_ksvm) <- "Mean"
  colnames(cv_sd_ksvm) <- "Sd"
  cv_all_ksvm <- cbind(cv_results_ksvm, cv_mean_ksvm, cv_sd_ksvm)
  kable(t(cv_all_ksvm),digits=2)
}

## cv_function for KNN (iBk) model 
cv_function_iBk <- function(df, target, nFolds, seedVal, metrics_list, k)
{
  set.seed(seedVal)
  folds = createFolds(df[,target],nFolds) 
  cv_results_iBk <- lapply(folds, function(x)
  { 
    test_target <- df[x,target]
    test_input  <- df[x,-target]
    train_target <- df[-x,target]
    train_input <- df[-x,-target]

    prediction_model_iBk <- IBk(train_target~.,data = train_input, control = Weka_control(K=k)) 
    pred_iBk <- predict(prediction_model_iBk,test_input)
    return(mmetric(test_target,pred_iBk,metrics_list))
  })
  
  cv_results_iBk <- as.matrix(as.data.frame(cv_results_iBk))
  cv_mean_iBk <- as.matrix(rowMeans(cv_results_iBk))
  cv_sd_iBk <- as.matrix(rowSds(cv_results_iBk))
  colnames(cv_mean_iBk) <- "Mean"
  colnames(cv_sd_iBk) <- "Sd"
  cv_all_iBk <- cbind(cv_results_iBk, cv_mean_iBk, cv_sd_iBk)
  kable(t(cv_all_iBk),digits=2)
}
```

# Three fold cross-validation of MLP, ksvm and IBk models
```{r Three fold cross-validation of MLP, ksvm and IBk models}
#6A Use default setting to perform cv for numeric prediction
df <- game_data
target <- 8
nFolds <- 3
seedVal <- 500
metrics_list <- c("MAE","MAPE","RAE","RMSE","RMSPE","RRSE","R2")

## MLP model - default
l <- 0.3
m <- 0.2
n <- 500
h <- 'a'
cv_function_MLP(df, target, nFolds, seedVal, metrics_list, l, m, n, h)

## SVM (ksvm) model - default
kern <- 'rbfdot'
c <- 1
cv_function_ksvm(df, target, nFolds, seedVal, metrics_list, kern, c)

## KNN (iBk) model - default 
k <- 1
cv_function_iBk(df, target, nFolds, seedVal, metrics_list, k)
```